{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#plt.rcParams['figure.figsize'] = (14, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_col(x):   \n",
    "    if len(x.shape)==1:\n",
    "        x=x.reshape(x.shape[0],1)\n",
    "    return x\n",
    "\n",
    "def to_line(x):\n",
    "    \"\"\" convert an vector to line vector if needed \"\"\"\n",
    "    if len(x.shape)==1:\n",
    "        x=x.reshape(1,x.shape[0])\n",
    "    return x\n",
    "\n",
    "def plot_data(data,labels=None):\n",
    "    \"\"\"\n",
    "    Affiche des donnees 2D\n",
    "    :param data: matrice des donnees 2d\n",
    "    :param labels: vecteur des labels (discrets)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    cols,marks = [\"red\", \"green\", \"blue\", \"orange\", \"black\", \"cyan\"],[\".\",\"+\",\"*\",\"o\",\"x\",\"^\"]\n",
    "    if labels is None:\n",
    "        plt.scatter(data[:,0],data[:,1],marker=\"x\")\n",
    "        return\n",
    "    for i,l in enumerate(sorted(list(set(labels.flatten())))):\n",
    "        plt.scatter(data[labels==l,0],data[labels==l,1],c=cols[i],marker=marks[i])\n",
    "        \n",
    "\n",
    "def make_grid(data=None,xmin=-5,xmax=5,ymin=-5,ymax=5,step=20):\n",
    "    \"\"\" Cree une grille sous forme de matrice 2d de la liste des points\n",
    "    :param data: pour calcluler les bornes du graphe\n",
    "    :param xmin: si pas data, alors bornes du graphe\n",
    "    :param xmax:\n",
    "    :param ymin:\n",
    "    :param ymax:\n",
    "    :param step: pas de la grille\n",
    "    :return: une matrice 2d contenant les points de la grille\n",
    "    \"\"\"\n",
    "    if data is not None:\n",
    "        xmax, xmin, ymax, ymin = np.max(data[:,0]),  np.min(data[:,0]), np.max(data[:,1]), np.min(data[:,1])\n",
    "    x, y =np.meshgrid(np.arange(xmin,xmax,(xmax-xmin)*1./step), np.arange(ymin,ymax,(ymax-ymin)*1./step))\n",
    "    grid=np.c_[x.ravel(),y.ravel()]\n",
    "    return grid, x, y\n",
    "\n",
    "\n",
    "def plot_frontiere(data,f,step=20):\n",
    "    \"\"\" Trace un graphe de la frontiere de decision de f\n",
    "    :param data: donnees\n",
    "    :param f: fonction de decision\n",
    "    :param step: pas de la grille\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    grid,x,y=make_grid(data=data,step=step)\n",
    "    plt.contourf(x,y,f(grid).reshape(x.shape),colors=('gray','blue'),levels=[-1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "#A_train = np.array([map(float,line.rstrip().split('\\t')) for line in open('classification_data_HWK1/classificationA.train')])\n",
    "#B_train = np.array([map(float,line.rstrip().split('\\t')) for line in open('classification_data_HWK1/classificationB.train')])\n",
    "#C_train = np.array([map(float,line.rstrip().split('\\t')) for line in open('classification_data_HWK1/classificationC.train')])\n",
    "#A_test = np.array([map(float,line.rstrip().split('\\t')) for line in open('classification_data_HWK1/classificationA.test')])\n",
    "#B_test = np.array([map(float,line.rstrip().split('\\t')) for line in open('classification_data_HWK1/classificationB.test')])\n",
    "#C_test = np.array([map(float,line.rstrip().split('\\t')) for line in open('classification_data_HWK1/classificationC.test')])\n",
    "\n",
    "#print(np.shape(A_train),np.shape(B_train),np.shape(C_train),np.shape(A_test),np.shape(B_test),np.shape(C_test))\n",
    "# bizarrement les testsets sont plus grand que les trainsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_train = np.loadtxt('classification_data_HWK1/classificationA.train')\n",
    "B_train = np.loadtxt('classification_data_HWK1/classificationB.train')\n",
    "C_train = np.loadtxt('classification_data_HWK1/classificationC.train')\n",
    "\n",
    "A_test = np.loadtxt('classification_data_HWK1/classificationA.test')\n",
    "B_test = np.loadtxt('classification_data_HWK1/classificationB.test')\n",
    "C_test = np.loadtxt('classification_data_HWK1/classificationC.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A_train\n",
    "#A_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_A_train = A_train[:,0:2]\n",
    "Y_A_train = to_col(A_train[:,2])\n",
    "#X_A_train,Y_A_train\n",
    "\n",
    "X_B_train = B_train[:,0:2]\n",
    "Y_B_train = to_col(B_train[:,2])\n",
    "#X_B_train,Y_B_train\n",
    "\n",
    "X_C_train = C_train[:,0:2]\n",
    "Y_C_train = to_col(C_train[:,2])\n",
    "#X_C_train,Y_C_train\n",
    "\n",
    "X_A_test = A_test[:,0:2]\n",
    "Y_A_test = to_col(A_test[:,2])\n",
    "#X_A_test,Y_A_test\n",
    "\n",
    "X_B_test = B_test[:,0:2]\n",
    "Y_B_test = to_col(B_test[:,2])\n",
    "#X_B_test,Y_B_test\n",
    "\n",
    "X_C_test = C_test[:,0:2]\n",
    "Y_C_test = to_col(C_test[:,2])\n",
    "#X_C_test,Y_C_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3)\n",
    "green, = axes[0][0].plot([a[0] for a in A_train if a[2]==1],[a[1] for a in A_train if a[2]==1],'go')\n",
    "blue, = axes[0][0].plot([a[0] for a in A_train if a[2]==0],[a[1] for a in A_train if a[2]==0],'bo')\n",
    "\n",
    "axes[0][1].plot([b[0] for b in B_train if b[2]==1],[b[1] for b in B_train if b[2]==1],'go')\n",
    "axes[0][1].plot([b[0] for b in B_train if b[2]==0],[b[1] for b in B_train if b[2]==0],'bo')\n",
    "\n",
    "axes[0][2].plot([c[0] for c in C_train if c[2]==1],[c[1] for c in C_train if c[2]==1],'go')\n",
    "axes[0][2].plot([c[0] for c in C_train if c[2]==0],[c[1] for c in C_train if c[2]==0],'bo')\n",
    "\n",
    "axes[1][0].plot([a[0] for a in A_test if a[2]==1],[a[1] for a in A_test if a[2]==1],'go')\n",
    "axes[1][0].plot([a[0] for a in A_test if a[2]==0],[a[1] for a in A_test if a[2]==0],'bo')\n",
    "\n",
    "axes[1][1].plot([b[0] for b in B_test if b[2]==1],[b[1] for b in B_test if b[2]==1],'go')\n",
    "axes[1][1].plot([b[0] for b in B_test if b[2]==0],[b[1] for b in B_test if b[2]==0],'bo')\n",
    "\n",
    "axes[1][2].plot([c[0] for c in C_test if c[2]==1],[c[1] for c in C_test if c[2]==1],'go')\n",
    "axes[1][2].plot([c[0] for c in C_test if c[2]==0],[c[1] for c in C_test if c[2]==0],'bo')\n",
    "\n",
    "axes[0][0].set_title(\"A\",fontsize=\"40\")\n",
    "axes[0][1].set_title(\"B\",fontsize=\"40\")\n",
    "axes[0][2].set_title(\"C\",fontsize=\"40\")\n",
    "axes[0][0].set_ylabel(\"Train\",fontsize=\"40\")\n",
    "axes[1][0].set_ylabel(\"Test\",fontsize=\"40\")\n",
    "fig.legend((green,blue),('1', '0'),'center right',numpoints = 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MLE Generative model (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#VERIFIER THETA\n",
    "def theta_MLE(Y):\n",
    "    return(np.sum(Y)/Y.shape[0])\n",
    "\n",
    "def mu_1_MLE(X,Y):\n",
    "    return([np.sum(Y*to_col(X[:,0]))/np.sum(Y), np.sum(Y*to_col(X[:,1]))/np.sum(Y)])\n",
    "\n",
    "def mu_0_MLE(X,Y): \n",
    "    return([(np.sum(X[:,0]) - np.sum(Y*to_col(X[:,0])))/(Y.shape[0]-np.sum(Y)), \n",
    "            (np.sum(X[:,1]) - np.sum(Y*to_col(X[:,1])))/(Y.shape[0]-np.sum(Y))])\n",
    "\n",
    "def sigma_MLE(X,Y): \n",
    "    s1 = np.dot(np.transpose(Y)*np.transpose(X-mu_1_MLE(X,Y)),(X-mu_1_MLE(X,Y)))\n",
    "    s2 = np.dot((np.ones(Y.shape[0])-np.transpose(Y))*np.transpose(X-mu_0_MLE(X,Y)),(X-mu_0_MLE(X,Y)))\n",
    "    return((s1+s2)/Y.shape[0])\n",
    "\n",
    "def sigmoid(X):  #fonction sigmoide pour la proba conditionnelle\n",
    "    return (1/(1+np.exp(-X)))\n",
    "\n",
    "def a_sigmoid(X,Y):\n",
    "    return(np.dot(np.linalg.inv(sigma_MLE(X,Y)),np.asarray(mu_1_MLE(X,Y))-np.asarray(mu_0_MLE(X,Y))))\n",
    "\n",
    "def b_sigmoid(X,Y):\n",
    "    return(np.log(theta_MLE(Y)/(1-theta_MLE(Y))) \n",
    "           -1/2*np.dot(np.dot((np.asarray(mu_1_MLE(X,Y))-np.asarray(mu_0_MLE(X,Y))),np.linalg.inv(sigma_MLE(X,Y)))\n",
    "                ,(np.asarray(mu_0_MLE(X,Y))+np.asarray(mu_1_MLE(X,Y)))))\n",
    "\n",
    "#def LDA(X,Y):\n",
    "#    return(sigmoid(a_sigmoid(X,Y)*X+b_sigmoid(X,Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta = 0.728464295933\n",
      "nu_1 = [-2.6923200424000004, 0.86604199999999987]\n",
      "nu_0 = [2.8997094650999999, -0.89387399999999984]\n",
      "sigma = [[ 2.44190897 -1.13194024]\n",
      " [-1.13194024  0.61375465]]\n",
      "a = [-6.62245258 -9.3462503 ]\n",
      "b = -0.136496290948\n"
     ]
    }
   ],
   "source": [
    "print(\"theta =\",theta_MLE(X_A_train))\n",
    "print(\"mu_1 =\",mu_1_MLE(X_A_train,Y_A_train))\n",
    "print(\"mu_0 =\",mu_0_MLE(X_A_train,Y_A_train))\n",
    "print(\"sigma =\",sigma_MLE(X_A_train,Y_A_train))\n",
    "print(\"a =\", a_sigmoid(X_A_train,Y_A_train))\n",
    "print(\"b =\", b_sigmoid(X_A_train,Y_A_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LDA(X_A_train,Y_A_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta = 0.1857928107\n",
      "nu_1 = [-3.2167073426666666, 1.0830673333333334]\n",
      "nu_0 = [3.340688964066667, -0.83546333333333334]\n",
      "sigma = [[ 3.34623467 -0.13516489]\n",
      " [-0.13516489  1.73807475]]\n",
      "a = [-1.92108197  0.95442836]\n",
      "b = 0.000929288716542\n"
     ]
    }
   ],
   "source": [
    "print(\"theta =\",theta_MLE(X_B_train))\n",
    "print(\"mu_1 =\",mu_1_MLE(X_B_train,Y_B_train))\n",
    "print(\"mu_0 =\",mu_0_MLE(X_B_train,Y_B_train))\n",
    "print(\"sigma =\",sigma_MLE(X_B_train,Y_B_train))\n",
    "print(\"a =\", a_sigmoid(X_B_train,Y_B_train))\n",
    "print(\"b =\", b_sigmoid(X_B_train,Y_B_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta = -1.70460019268\n",
      "nu_1 = [-2.9423288508400001, -0.95782840000000014]\n",
      "nu_0 = [2.7930482376000003, -0.8383866666666665]\n",
      "sigma = [[ 2.88039225 -0.63405081]\n",
      " [-0.63405081  5.19952435]]\n",
      "a = [-2.05129911 -0.27311529]\n",
      "b = 0.112429132177\n"
     ]
    }
   ],
   "source": [
    "print(\"theta =\",theta_MLE(X_C_train))\n",
    "print(\"mu_1 =\",mu_1_MLE(X_C_train,Y_C_train))\n",
    "print(\"mu_0 =\",mu_0_MLE(X_C_train,Y_C_train))\n",
    "print(\"sigma =\",sigma_MLE(X_C_train,Y_C_train))\n",
    "print(\"a =\", a_sigmoid(X_C_train,Y_C_train))\n",
    "print(\"b =\", b_sigmoid(X_C_train,Y_C_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. QDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigma_0_MLE(X,Y):\n",
    "    return()\n",
    "\n",
    "def sigma_1_MLE(X,Y):\n",
    "    return()\n",
    "\n",
    "\n",
    "def c_sigmoid(X,Y):\n",
    "    return(np.dot(np.linalg.inv(sigma_1_MLE(X,Y)),np.asarray(nu_1_MLE(X,Y)))\n",
    "           -np.dot(np.linalg.inv(sigma_0_MLE(X,Y)),np.asarray(nu_0_MLE(X,Y)))\n",
    "           \n",
    "           \n",
    "           \n",
    "           np.asarray(nu_0_MLE(X,Y))))\n",
    "\n",
    "def d_sigmoid(X,Y):\n",
    "    return(np.log(theta_MLE(Y)/(1-theta_MLE(Y))) \n",
    "           -1/2*np.dot(np.dot((np.asarray(nu_1_MLE(X,Y))-np.asarray(nu_0_MLE(X,Y))),np.linalg.inv(sigma_MLE(X,Y)))\n",
    "                ,(np.asarray(nu_0_MLE(X,Y))+np.asarray(nu_1_MLE(X,Y)))))\n",
    "\n",
    "def M_sigmoid(X,Y):\n",
    "    return(np.dot(np.linalg.inv(sigma_MLE(X,Y)),np.asarray(nu_1_MLE(X,Y))-np.asarray(nu_0_MLE(X,Y))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LDA(X_A_train, Y_A_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Theta_MLE_A = (1.0/np.shape(A_train)[0])*sum([a[2] for a in A_train])\n",
    "Theta_MLE_B = (1.0/np.shape(B_train)[0])*sum([b[2] for b in B_train])\n",
    "Theta_MLE_C = (1.0/np.shape(C_train)[0])*sum([c[2] for c in C_train])\n",
    "\n",
    "print Theta_MLE_A\n",
    "print Theta_MLE_B\n",
    "print Theta_MLE_C\n",
    "\n",
    "mu_0_MLE_A = np.sum([(1-a[2])*np.array([a[0],a[1]]) for a in A_train],axis = 0)/sum([(1-a[2]) for a in A_train])\n",
    "mu_0_MLE_B = np.sum([(1-b[2])*np.array([b[0],b[1]]) for b in B_train],axis = 0)/sum([(1-b[2]) for b in B_train])\n",
    "mu_0_MLE_C = np.sum([(1-c[2])*np.array([c[0],c[1]]) for c in C_train],axis = 0)/sum([(1-c[2]) for c in C_train])\n",
    "\n",
    "print mu_0_MLE_A\n",
    "print mu_0_MLE_B\n",
    "print mu_0_MLE_C\n",
    "\n",
    "mu_1_MLE_A = np.sum([a[2]*np.array([a[0],a[1]]) for a in A_train],axis = 0)/sum([a[2] for a in A_train])\n",
    "mu_1_MLE_B = np.sum([b[2]*np.array([b[0],b[1]]) for b in B_train],axis = 0)/sum([b[2] for b in B_train])\n",
    "mu_1_MLE_C = np.sum([c[2]*np.array([c[0],c[1]]) for c in C_train],axis = 0)/sum([c[2] for c in C_train])\n",
    "\n",
    "print mu_1_MLE_A\n",
    "print mu_1_MLE_B\n",
    "print mu_1_MLE_C\n",
    "\n",
    "def p_Y1_X(x,theta,mu_0,mu_1,sigma):#x vecteur vertical\n",
    "    return( 1.0/(1.0+((1.0-theta)/(theta))*exp((((mu_0+mu_1)[np.newaxis]).T).dot(sigma).dot(x) - (1.0/2)*((mu_0.T).dot(sigma).dot(mu_0) + (mu_1.T).dot(sigma).dot(mu_1))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print A_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print [np.array([a[0],a[1]]) for a in A_train][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2])\n",
    "b = np.array([[3,4],[5,6]])\n",
    "print np.transpose(a[np.newaxis])*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transformer un vecteur ligne en colone\n",
    "vecteur_ligne = np.array([1,2,3])\n",
    "vecteur_colone = np.transpose(vecteur_ligne[np.newaxis])\n",
    "print vecteur_ligne\n",
    "print np.transpose(vecteur_colone).dot(np.array([[1,2,0],[0,1,0],[0,0,1]])).dot(vecteur_colone)\n",
    "\n",
    "print vecteur_colone.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#logistic regression\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
